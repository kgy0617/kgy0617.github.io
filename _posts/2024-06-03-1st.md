
## 🔍 왜 비교했는가?

최근 실시간 음성 번역 웹앱을 개발하면서 가장 먼저 고민한 것은 바로 **음성 인식 엔진**이었습니다. 대표적인 오픈소스 기반의 [Whisper](https://github.com/openai/whisper)와 상용 API 기반의 [Google Cloud Speech-to-Text(STT)](https://cloud.google.com/speech-to-text)를 비교해 보았습니다.

- Whisper: 로컬에서 작동 가능, GPT 계열로 학습된 모델
- Google STT: 클라우드 API 기반, 빠른 응답 속도와 높은 정확도

<br>

## ⚙️ 실험 환경

| 항목 | 설명 |
|------|------|
| 입력 음성 | TED 스피치 샘플 (영어, 1분 분량) |
| 테스트 조건 | 1) 실시간 스트리밍<br>2) 네트워크 상태 안정적 |
| 비교 항목 | 정확도, 속도, 자원 사용, 실시간성 |

<br>

## 🧪 비교 결과

### 📌 1. 정확도 (Accuracy)
- **Whisper (medium.en)**: 문장 단위로 인식 정확도 높음, 억양이나 속도에 민감
- **Google STT**: 실시간 정확도 매우 우수, 억양/발음 변화에도 강인함

> 예시 문장  
> - 입력: *"Artificial intelligence is transforming the world."*  
> - Whisper: `"Artificial intelligent is transforming the world"` ❌  
> - Google STT: `"Artificial intelligence is transforming the world"` ✅

---

### ⚡ 2. 응답 속도 (Latency)
- **Whisper**: 평균 1~2초 지연
- **Google STT**: 거의 실시간 수준 (200~500ms)

Whisper는 로컬 디코딩 시간이 있어 약간의 딜레이가 발생합니다.

---

### 💻 3. 자원 사용 (Resource Usage)
- **Whisper**: GPU/CPU 사용량 높음, 로컬 머신에서 실행 시 발열 및 점유율 부담
- **Google STT**: 클라우드 기반이므로 클라이언트 자원 부담 거의 없음

---

### 🔁 4. 실시간 스트리밍 처리
- **Whisper**: streaming이 가능하지만, 직접 구현 필요 (ex. `faster-whisper`, `whisper-live`)
- **Google STT**: streaming API 기본 제공 (WebSocket 방식)

---

## ✅ 결론

| 항목 | Whisper | Google STT |
|------|---------|------------|
| 정확도 | 높음 (전처리 필요 시 더 강력) | 매우 우수 |
| 실시간성 | 상대적으로 느림 | 빠름 |
| 구축 난이도 | 쉬움 (오픈소스) | API 인증 및 결제 필요 |
| 자원 | 로컬 리소스 사용 | 클라우드 사용 |

**👉 실시간 회의 통역, 모바일 앱, 빠른 응답이 필요한 상황**에서는 Google STT  
**👉 로컬에서 독립적으로 운영하거나 번역 품질을 최적화하고 싶은 경우**는 Whisper가 적합합니다.

---

## 🔧 사용한 도구 및 코드

- [Whisper 공식 깃허브](https://github.com/openai/whisper)
- [faster-whisper (실시간용 경량 모델)](https://github.com/guillaumekln/faster-whisper)
- [Google Cloud STT Streaming Docs](https://cloud.google.com/speech-to-text/docs/streaming-recognize)

---

## 📌 참고: 제가 만든 실시간 음성 번역기

> [🔗 GitHub 프로젝트 보기](https://github.com/kgy0617/translator)  
> 영어를 실시간으로 인식하고 자연스러운 한국어로 번역하는 웹앱, Streamlit 기반 UI 포함

---

